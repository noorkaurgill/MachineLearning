{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": true,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "noor_gill_project2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNALzZOKTzOS"
      },
      "source": [
        "# Digit Classification Naive Bayes\n",
        "\n"      ]
    },

    {
      "cell_type": "code",
      "metadata": {
        "id": "r8u7GmsDTzOX"
      },
      "source": [
        "# This tells matplotlib not to try opening a new window for each plot.\n",
        "%matplotlib inline\n",
        "\n",
        "# Import a bunch of libraries.\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import MultipleLocator\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "\n",
        "# Set the randomizer seed so results are the same each time.\n",
        "np.random.seed(0)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWOWoq_dTzOY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a2b4613a-5932-46d0-acdc-f22b6087632d"
      },
      "source": [
        "import sklearn\n",
        "sklearn.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'0.22.2.post1'"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1-CAjA9TzOa"
      },
      "source": [
        "Load the data. Notice that the data gets partitioned into training, development, and test sets. Also, a small subset of the training data called mini_train_data and mini_train_labels gets defined, which you should use in all the experiments below, unless otherwise noted."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9kPmCW0TzOb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "050b9a32-c786-49ff-9c8a-0ef819be0e85"
      },
      "source": [
        "# Load the digit data from https://www.openml.org/d/554 or from default local location '~/scikit_learn_data/...'\n",
        "X, Y = fetch_openml(name='mnist_784', return_X_y=True, cache=False, as_frame=False)\n",
        "\n",
        "# Rescale grayscale values to [0,1].\n",
        "X = X / 255.0\n",
        "\n",
        "# Shuffle the input: create a random permutation of the integers between 0 and the number of data points and apply this\n",
        "# permutation to X and Y.\n",
        "# NOTE: Each time you run this cell, you'll re-shuffle the data, resulting in a different ordering.\n",
        "shuffle = np.random.permutation(np.arange(X.shape[0]))\n",
        "X, Y = X[shuffle], Y[shuffle]\n",
        "\n",
        "print('data shape: ', X.shape)\n",
        "print('label shape:', Y.shape)\n",
        "\n",
        "# Set some variables to hold test, dev, and training data.\n",
        "test_data, test_labels = X[61000:], Y[61000:]\n",
        "dev_data, dev_labels = X[60000:61000], Y[60000:61000]\n",
        "train_data, train_labels = X[:60000], Y[:60000]\n",
        "mini_train_data, mini_train_labels = X[:1000], Y[:1000]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data shape:  (70000, 784)\n",
            "label shape: (70000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gr40-NstTzOl"
      },
      "source": [
        "### Question 1: Applying a smoothing using numpy.\n",
        "---\n",
        "\n",
        "A common image processing technique is to smooth an image by **blurring**. The idea is that the value of a particular pixel is estimated as the weighted combination of the original value and the values around it. Typically, the blurring is Gaussian, i.e., the weight of a pixel's influence is determined by a Gaussian function over the distance to the relevant pixel.\n",
        "\n",
        "1. Implement a simplified Gaussian blur filter by just using the 8 neighboring pixels like this: the smoothed value of a pixel is a weighted combination of the original value and the 8 neighboring values.\n",
        "1. Choose some weights as a starting point. Produce and evaluate four 1-Nearest Neighbor models by applying your blur filter in these ways:\n",
        "  1. Do not use the filter\n",
        "  1. Filter the training data but not the dev data\n",
        "  1. Filter the dev data but not the training data\n",
        "  1. Filter both training data and dev data\n",
        "1. Show the accuracies of the four models evaluated as described. What do you see? Can you explain why this is?\n",
        "1. Experiment with weights that makes one model's accuracy at least 0.9.\n",
        "\n",
        "Notes:\n",
        "* Train on the (filtered) mini train set.\n",
        "* Evaluate performance on the (filtered) dev set.\n",
        "* A good trick to simplify your code is to use numpy's pad function to add 0s around your original array so you don't have to deal with \"edge cases\".\n",
        "* In addition, you can use numpy to multiply and sum slices of two arrays.\n",
        "* [This notebook](https://colab.research.google.com/drive/1eJXTQLtREXQjQIsLOA9uCrBl6B049-pO) might help shows some example numpy code.\n",
        "* In general, [numpy operations will be much faster than for loops](https://colab.research.google.com/drive/1KJI4JtuIqVdyZHTTe_mAlKYA5XdLFp3_). \n",
        "* There are other Guassian blur filters available, for example in `scipy.ndimage.filters`. You are welcome to experiment with those, but in this question, please implement your own."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebHGUU0eTzOl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7697ea1-08be-4d82-d724-1d0c37e13a5a"
      },
      "source": [
        "def Q1():\n",
        "  '''Implement a simplified Gaussian blur filter by just using the 8 neighboring pixels and applies in 4 different ways with respective model accuracies'''\n",
        "### STUDENT START ##\n",
        "  # Defining the weights: \n",
        "  weights = 1/9 * np.ones((3,3))\n",
        "  def blur(data, weights):\n",
        "    '''Helper function that blurs each image in a dataset'''\n",
        "    # Creating a new array of the same shape as the data, but with placeholder 0's: \n",
        "    blurred = np.zeros((28,28))\n",
        "    # Using np.pad to create a border of extra 0s in the original array to help with edge cases: \n",
        "    data = np.pad(data.reshape(28, 28), 1)\n",
        "    # Creating a nested for loop to iterate through the data:\n",
        "    for row in range(28): \n",
        "      for column in range(28): \n",
        "        #Updating each value to be the weighted average of each slice of neighbors around that value and multiplying the neighbors matrix by the weights:\n",
        "        blurred[row, column] = np.sum(data[row:row + 3, column:column + 3] * weights)\n",
        "    return blurred\n",
        "\n",
        "  # Filtering the mini train data and dev data as their own variables, making sure to reshape the data for subsequent steps:\n",
        "  blurred_mini_train_data = [blur(image.reshape((28, 28)), weights) for image in mini_train_data]\n",
        "  blurred_mini_train_data = np.array(blurred_mini_train_data).reshape((1000, 784))\n",
        "\n",
        "  blurred_dev_data = [blur(image.reshape((28, 28)), weights) for image in dev_data]\n",
        "  blurred_dev_data = np.array(blurred_dev_data).reshape((1000, 784))\n",
        "\n",
        "  # Producing and evaluating four 1-Nearest Neighbor models by applying the blur filter in the 4 ways specified in the directions: \n",
        "  print(\"1. Do not use the filter\")\n",
        "  model1 = KNeighborsClassifier(n_neighbors=1)\n",
        "  model1.fit(mini_train_data, mini_train_labels)\n",
        "  model1_predictions = model1.predict(dev_data) \n",
        "  print(\"Model Accuracy: \" + str(accuracy_score(dev_labels, model1_predictions)))\n",
        "  print('\\n') \n",
        "\n",
        "  print(\"2. Filter the training data but not the dev data\")\n",
        "  model2 = KNeighborsClassifier(n_neighbors=1)\n",
        "  model2.fit(blurred_mini_train_data, mini_train_labels)\n",
        "  model2_predictions = model2.predict(dev_data) \n",
        "  print(\"Model Accuracy: \" + str(accuracy_score(dev_labels, model2_predictions)))\n",
        "  print('\\n') \n",
        "\n",
        "  print(\"3. Filter the dev data but not the training data\")\n",
        "  model3 = KNeighborsClassifier(n_neighbors=1)\n",
        "  model3.fit(mini_train_data, mini_train_labels)\n",
        "  model3_predictions = model3.predict(blurred_dev_data) \n",
        "  print(\"Model Accuracy: \" + str(accuracy_score(dev_labels, model3_predictions)))\n",
        "  print('\\n') \n",
        "\n",
        "  print(\"4. Filter both training data and dev data\")\n",
        "  model4 = KNeighborsClassifier(n_neighbors=1)\n",
        "  model4.fit(blurred_mini_train_data, mini_train_labels)\n",
        "  model4_predictions = model4.predict(blurred_dev_data) \n",
        "  print(\"Model Accuracy: \" + str(accuracy_score(dev_labels, model4_predictions)))\n",
        "  print('\\n') \n",
        "  ### STUDENT END ###\n",
        "\n",
        "Q1()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Do not use the filter\n",
            "Model Accuracy: 0.884\n",
            "\n",
            "\n",
            "2. Filter the training data but not the dev data\n",
            "Model Accuracy: 0.907\n",
            "\n",
            "\n",
            "3. Filter the dev data but not the training data\n",
            "Model Accuracy: 0.868\n",
            "\n",
            "\n",
            "4. Filter both training data and dev data\n",
            "Model Accuracy: 0.905\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqcBy1LXnIkD"
      },
      "source": [
        "ANSWER: As observed with the model accuracies above, the model score ranges from 86.8% to 90.7%, with an average model accuracy of about 89.1%. The difference between the accuracies of the models is very small in the case where I filter the mini train data, with a difference of about 0.2%. The accuracy is the greatest (90.7%) when the mini train data is blurred, but the dev data is not. This is reasonable since pre-processing the training data by blurring it can make it more generalizable when predicting the dev data, whereas generalizing the dev data does not make sense. \n",
        "\n",
        "In terms of experimenting with weights that make model accuracy atleast 0.9, I used a method that yields the weighted average of each slice of neighbors around that value, which yielede a relatively high accuracy.\n",
        "\n",
        "1/(value + 8 neighboring values = 9) * np.ones(((value + value to the left + value to the right = 3),value + value to the left + value to the right = 3())\n",
        "\n",
        "--> Based on Kernel Filters Notebook provided:)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aN3HZPGuTzOn"
      },
      "source": [
        "### Question 2: Modeling your data and experimenting with different Naive Bayes models. \n",
        "---\n",
        "\n",
        "1. Produce two Naive Bayes models and evaluate their performances.  Recall that Naive Bayes estimates P(feature|label), where each label is a categorical, not a real number.\n",
        "  1. For the first model, map pixel values to either 0 or 1, representing white or black - you should pre-process the data or use `BernoulliNB`'s `binarize` parameter to set the white/black separation threshold to 0.1.  Use `BernoulliNB` to produce the model.\n",
        "  1. For the second model, map pixel values to either 0, 1, or 2, representing white, gray, or black - you should pre-process the data, seting the white/gray/black separation thresholds to 0.1 and 0.9.  Here you'll likely need to implement a `trianarize` helper function. Since we are going beyond the binary representation of our features, you should use `MultinomialNB` to produce the model.\n",
        "1. Show the Bernoulli model accuracy and the Multinomial model accuracy.\n",
        "1. Does the multinomial version improve the results? Why or why not?\n",
        "\n",
        "Notes:\n",
        "* Train on the mini train set.\n",
        "* Evaluate performance on the dev set.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1edM3ehTzOn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5a2ae0f-5632-44a9-f026-3b070fe635a0"
      },
      "source": [
        "# Solution with binarization by explicit binarize function\n",
        "\n",
        "def Q2():\n",
        "  '''Produces 2 Naive Bayes models (Bernoulli and Multinomial) and evaluates their performances'''\n",
        "\n",
        "### STUDENT START ###\n",
        "  # Developing explicit binarize function that maps pixel values to either 0 or 1, representing white or black (with a threshold of 0.1):\n",
        "  def binarize(data):\n",
        "    '''Maps pixel values to either 0 or 1, representing white or black (with a threshold of 0.1)'''\n",
        "    data[np.where(mini_train_data < 0.1)] = 0\n",
        "    data[np.where(mini_train_data >= 0.1)] = 1\n",
        "    return data\n",
        "\n",
        "  #Binarizing the mini train data: \n",
        "  binarized_mini_train_data = binarize(mini_train_data)\n",
        "    \n",
        "  # Using BernoulliNB to produce the model (Alternate Method: BernoulliNB(binarize = 0.1)): \n",
        "  binary_nb = BernoulliNB()\n",
        "  # Fitting the model on the binarized mini train data and mini train labels: \n",
        "  binary_nb.fit(binarized_mini_train_data, mini_train_labels)\n",
        "\n",
        "  # Predicting on dev data: \n",
        "  binary_nb_predicted = binary_nb.predict(dev_data)\n",
        "  # Obtaining accuracy of the model using accuracy_score and normalization: \n",
        "  binary_nb_accuracy_score = accuracy_score(dev_labels, binary_nb_predicted, normalize=True)\n",
        "\n",
        "  # Printing evaluation: \n",
        "  print(\"Bernoulli Model Accuracy: \" + str(binary_nb_accuracy_score))\n",
        "\n",
        "  # Developing trianarize function that map pixel values to either 0, 1, or 2, representing white, gray, or black - setting the white/gray/black separation thresholds to 0.1 and 0.9:\n",
        "  def trianarize(data):\n",
        "    '''Maps pixel values to either 0, 1, or 2, representing white, gray, or black (with thresholds of 0.1 and 0.9)'''\n",
        "    data[np.where(mini_train_data >= 0.9)] = 2\n",
        "    data[np.where((mini_train_data >= 0.1) & (mini_train_data < 0.9))] = 1\n",
        "    data[np.where(mini_train_data < 0.1)] = 0\n",
        "    return data\n",
        "\n",
        "  # Creating a mutable copy of the mini train data for subsequent steps:\n",
        "  mini_train_data_copy = mini_train_data.copy()\n",
        "\n",
        "  # Trianarizing the mini train data: \n",
        "  trianarized_mini_train_data = trianarize(mini_train_data_copy)\n",
        "\n",
        "  # Using MultinomialNB to produce the model: \n",
        "  multinomial_nb = MultinomialNB()\n",
        "  # Fitting the model on the trianarized mini train data and mini train labels: \n",
        "  multinomial_nb.fit(trianarized_mini_train_data, mini_train_labels)\n",
        "\n",
        "  # Predicting on the dev data: \n",
        "  multinomial_nb_predicted = multinomial_nb.predict(dev_data)\n",
        "  # Obtaining accuracy of the model using accuracy_score and normalization: \n",
        "  multinomial_nb_accuracy_score = multinomial_nb.score(dev_data, dev_labels)\n",
        "\n",
        "  # Printing evaluation: \n",
        "  print(\"Multinomial Model Accuracy: \" + str(multinomial_nb_accuracy_score))\n",
        "### STUDENT END ###\n",
        "\n",
        "Q2()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bernoulli Model Accuracy: 0.816\n",
            "Multinomial Model Accuracy: 0.797\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bbbpzl5ETzOp"
      },
      "source": [
        "ANSWER: The multinomial version did not improve the results because the accuracy is 0.797 compared to 0.816 for the bernoulli version. This could because we splitting the data into either white, gray, or black may not contribute to better prediction, and may instead add noise, since most of the data is either black or white. Hence, the image may be roughly binarized with high pixel values of black and low pixel values of white, with very little to none medium pixel values of gray. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymzuQZwsTzOp"
      },
      "source": [
        "### Question 3: Applying the grid search technique.\n",
        "1. Search across several values of the LaPlace smoothing parameter (alpha) to find its effect on a Bernoulli Naive Bayes model's performance.  Show the accuracy at each alpha value.\n",
        "1. What is the best value for alpha? What is the accuracy when alpha is near 0? Is this what you'd expect?\n",
        "\n",
        "Notes:\n",
        "* Set binarization threshold to 0.\n",
        "* Train on the mini train set.\n",
        "* Evaluate performance by 5-fold cross-validation. \n",
        "* Use `GridSearchCV(..., ..., cv=..., scoring='accuracy', iid=False)` to vary alpha and evaluate performance by cross-validation.\n",
        "* Cross-validation is based on partitions of the training data, so results will be a bit different than if you had used the dev set to evaluate performance.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qc1fG0OTzOq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26f54d3e-b643-40c9-dc92-a57c28bd3112"
      },
      "source": [
        "def Q3(alphas):\n",
        "  '''Takes in a list of alpha values and searches across several values of the LaPlace smoothing parameter to find its effect on a Bernoulli Naive Bayes model's performance'''\n",
        "### STUDENT START ###\n",
        "  # Preparing the cross-validation procedure\n",
        "  cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
        "  # Using BernoulliNB to produce the model, setting the binarization threshold to 0: \n",
        "  model = BernoulliNB(binarize = 0)\n",
        "  # Evaluating the model using 5-fold cross validation: \n",
        "  scores = cross_val_score(model, mini_train_data, mini_train_labels, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "  # Reporting performance\n",
        "  print(\"Model Accuracy (Initial): \" +  str(np.mean(scores)))\n",
        "\n",
        "  # Using GridSearchCV(..., ..., cv=..., scoring='accuracy', iid=False) to vary alpha and evaluate performance by cross-validation:\n",
        "  grid_search = GridSearchCV(model, alphas, scoring='accuracy', verbose=3, cv=5, iid=False)\n",
        "  # Fitting on the mini train data and mini train labels:\n",
        "  grid_search.fit(mini_train_data, mini_train_labels)\n",
        "\n",
        "  # Printing the best value for alpha: \n",
        "  print(\"Best Alpha Parameter:\", grid_search.best_params_)\n",
        "  # Printing the summary of time results for all alphas: \n",
        "  print(\"Model Accuracy With Best Alpha Parameter: \" + str(grid_search.best_score_))\n",
        "\n",
        "  # Testing performance on alpha value closest to 0: \n",
        "  bernoulli_nb_smallest_alpha = BernoulliNB(binarize = alphas.get(0)) \n",
        "  # Fitting the model on the mini train data and mini train labels: \n",
        "  bernoulli_nb_smallest_alpha_fit = bernoulli_nb_smallest_alpha.fit(mini_train_data, mini_train_labels)\n",
        "  # Evaluating the model using 5-fold cross validation: \n",
        "  scores = cross_val_score(bernoulli_nb_smallest_alpha, mini_train_data, mini_train_labels, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "  # Reporting performance\n",
        "  print(\"Model Accuracy With Alpha Near 0: \" +  str(np.mean(scores)))\n",
        "\n",
        "  return grid_search.cv_results_\n",
        "### STUDENT END ###\n",
        "\n",
        "alphas = {'alpha': [1.0e-10, 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 10.0]}\n",
        "Q3(alphas)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy (Initial): 0.8119999999999999\n",
            "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
            "[CV] alpha=1e-10 .....................................................\n",
            "[CV] ......................... alpha=1e-10, score=0.875, total=   0.0s\n",
            "[CV] alpha=1e-10 .....................................................\n",
            "[CV] ......................... alpha=1e-10, score=0.755, total=   0.0s\n",
            "[CV] alpha=1e-10 .....................................................\n",
            "[CV] ......................... alpha=1e-10, score=0.855, total=   0.0s\n",
            "[CV] alpha=1e-10 .....................................................\n",
            "[CV] ......................... alpha=1e-10, score=0.790, total=   0.0s\n",
            "[CV] alpha=1e-10 .....................................................\n",
            "[CV] ......................... alpha=1e-10, score=0.840, total=   0.0s\n",
            "[CV] alpha=0.0001 ....................................................\n",
            "[CV] ........................ alpha=0.0001, score=0.870, total=   0.0s\n",
            "[CV] alpha=0.0001 ....................................................\n",
            "[CV] ........................ alpha=0.0001, score=0.770, total=   0.0s\n",
            "[CV] alpha=0.0001 ....................................................\n",
            "[CV] ........................ alpha=0.0001, score=0.855, total=   0.0s\n",
            "[CV] alpha=0.0001 ....................................................\n",
            "[CV] ........................ alpha=0.0001, score=0.790, total=   0.0s\n",
            "[CV] alpha=0.0001 ....................................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] ........................ alpha=0.0001, score=0.845, total=   0.0s\n",
            "[CV] alpha=0.001 .....................................................\n",
            "[CV] ......................... alpha=0.001, score=0.875, total=   0.0s\n",
            "[CV] alpha=0.001 .....................................................\n",
            "[CV] ......................... alpha=0.001, score=0.765, total=   0.0s\n",
            "[CV] alpha=0.001 .....................................................\n",
            "[CV] ......................... alpha=0.001, score=0.850, total=   0.0s\n",
            "[CV] alpha=0.001 .....................................................\n",
            "[CV] ......................... alpha=0.001, score=0.790, total=   0.0s\n",
            "[CV] alpha=0.001 .....................................................\n",
            "[CV] ......................... alpha=0.001, score=0.850, total=   0.0s\n",
            "[CV] alpha=0.01 ......................................................\n",
            "[CV] .......................... alpha=0.01, score=0.880, total=   0.0s\n",
            "[CV] alpha=0.01 ......................................................\n",
            "[CV] .......................... alpha=0.01, score=0.765, total=   0.0s\n",
            "[CV] alpha=0.01 ......................................................\n",
            "[CV] .......................... alpha=0.01, score=0.850, total=   0.0s\n",
            "[CV] alpha=0.01 ......................................................\n",
            "[CV] .......................... alpha=0.01, score=0.795, total=   0.0s\n",
            "[CV] alpha=0.01 ......................................................\n",
            "[CV] .......................... alpha=0.01, score=0.855, total=   0.0s\n",
            "[CV] alpha=0.1 .......................................................\n",
            "[CV] ........................... alpha=0.1, score=0.855, total=   0.0s\n",
            "[CV] alpha=0.1 .......................................................\n",
            "[CV] ........................... alpha=0.1, score=0.770, total=   0.0s\n",
            "[CV] alpha=0.1 .......................................................\n",
            "[CV] ........................... alpha=0.1, score=0.850, total=   0.0s\n",
            "[CV] alpha=0.1 .......................................................\n",
            "[CV] ........................... alpha=0.1, score=0.770, total=   0.0s\n",
            "[CV] alpha=0.1 .......................................................\n",
            "[CV] ........................... alpha=0.1, score=0.850, total=   0.0s\n",
            "[CV] alpha=0.5 .......................................................\n",
            "[CV] ........................... alpha=0.5, score=0.850, total=   0.0s\n",
            "[CV] alpha=0.5 .......................................................\n",
            "[CV] ........................... alpha=0.5, score=0.775, total=   0.0s\n",
            "[CV] alpha=0.5 .......................................................\n",
            "[CV] ........................... alpha=0.5, score=0.865, total=   0.0s\n",
            "[CV] alpha=0.5 .......................................................\n",
            "[CV] ........................... alpha=0.5, score=0.775, total=   0.0s\n",
            "[CV] alpha=0.5 .......................................................\n",
            "[CV] ........................... alpha=0.5, score=0.850, total=   0.0s\n",
            "[CV] alpha=1.0 .......................................................\n",
            "[CV] ........................... alpha=1.0, score=0.845, total=   0.0s\n",
            "[CV] alpha=1.0 .......................................................\n",
            "[CV] ........................... alpha=1.0, score=0.770, total=   0.0s\n",
            "[CV] alpha=1.0 .......................................................\n",
            "[CV] ........................... alpha=1.0, score=0.845, total=   0.0s\n",
            "[CV] alpha=1.0 .......................................................\n",
            "[CV] ........................... alpha=1.0, score=0.775, total=   0.0s\n",
            "[CV] alpha=1.0 .......................................................\n",
            "[CV] ........................... alpha=1.0, score=0.840, total=   0.0s\n",
            "[CV] alpha=2.0 .......................................................\n",
            "[CV] ........................... alpha=2.0, score=0.845, total=   0.0s\n",
            "[CV] alpha=2.0 .......................................................\n",
            "[CV] ........................... alpha=2.0, score=0.775, total=   0.0s\n",
            "[CV] alpha=2.0 .......................................................\n",
            "[CV] ........................... alpha=2.0, score=0.850, total=   0.0s\n",
            "[CV] alpha=2.0 .......................................................\n",
            "[CV] ........................... alpha=2.0, score=0.770, total=   0.0s\n",
            "[CV] alpha=2.0 .......................................................\n",
            "[CV] ........................... alpha=2.0, score=0.840, total=   0.0s\n",
            "[CV] alpha=10.0 ......................................................\n",
            "[CV] .......................... alpha=10.0, score=0.825, total=   0.0s\n",
            "[CV] alpha=10.0 ......................................................\n",
            "[CV] .......................... alpha=10.0, score=0.790, total=   0.0s\n",
            "[CV] alpha=10.0 ......................................................\n",
            "[CV] .......................... alpha=10.0, score=0.810, total=   0.0s\n",
            "[CV] alpha=10.0 ......................................................\n",
            "[CV] .......................... alpha=10.0, score=0.715, total=   0.0s\n",
            "[CV] alpha=10.0 ......................................................\n",
            "[CV] .......................... alpha=10.0, score=0.815, total=   0.0s\n",
            "Best Alpha Parameter: {'alpha': 0.01}\n",
            "Model Accuracy With Best Alpha Parameter: 0.829\n",
            "Model Accuracy With Alpha Near 0: 0.8119999999999999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:    1.0s finished\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:823: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
            "  \"removed in 0.24.\", FutureWarning\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mean_fit_time': array([0.01671109, 0.01695137, 0.01778393, 0.01487727, 0.01592398,\n",
              "        0.01468124, 0.02122149, 0.01534243, 0.01741242]),\n",
              " 'mean_score_time': array([0.00363231, 0.00339637, 0.00333915, 0.00361619, 0.0032969 ,\n",
              "        0.0032939 , 0.00334129, 0.0034863 , 0.00353584]),\n",
              " 'mean_test_score': array([0.823, 0.826, 0.826, 0.829, 0.819, 0.823, 0.815, 0.816, 0.791]),\n",
              " 'param_alpha': masked_array(data=[1e-10, 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 10.0],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'params': [{'alpha': 1e-10},\n",
              "  {'alpha': 0.0001},\n",
              "  {'alpha': 0.001},\n",
              "  {'alpha': 0.01},\n",
              "  {'alpha': 0.1},\n",
              "  {'alpha': 0.5},\n",
              "  {'alpha': 1.0},\n",
              "  {'alpha': 2.0},\n",
              "  {'alpha': 10.0}],\n",
              " 'rank_test_score': array([4, 2, 2, 1, 6, 4, 8, 7, 9], dtype=int32),\n",
              " 'split0_test_score': array([0.875, 0.87 , 0.875, 0.88 , 0.855, 0.85 , 0.845, 0.845, 0.825]),\n",
              " 'split1_test_score': array([0.755, 0.77 , 0.765, 0.765, 0.77 , 0.775, 0.77 , 0.775, 0.79 ]),\n",
              " 'split2_test_score': array([0.855, 0.855, 0.85 , 0.85 , 0.85 , 0.865, 0.845, 0.85 , 0.81 ]),\n",
              " 'split3_test_score': array([0.79 , 0.79 , 0.79 , 0.795, 0.77 , 0.775, 0.775, 0.77 , 0.715]),\n",
              " 'split4_test_score': array([0.84 , 0.845, 0.85 , 0.855, 0.85 , 0.85 , 0.84 , 0.84 , 0.815]),\n",
              " 'std_fit_time': array([0.00428037, 0.00382578, 0.00481941, 0.00030533, 0.00099654,\n",
              "        0.00016989, 0.00450428, 0.00063312, 0.00223401]),\n",
              " 'std_score_time': array([8.06352445e-04, 6.38220485e-05, 8.92328602e-05, 7.44724063e-04,\n",
              "        2.92295344e-05, 1.10497749e-04, 2.76707744e-05, 2.45218515e-04,\n",
              "        1.32520381e-04]),\n",
              " 'std_test_score': array([0.04411349, 0.03891015, 0.04140048, 0.04235564, 0.04004997,\n",
              "        0.03957272, 0.03478505, 0.03569314, 0.03967367])}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6g4fnGFPTzOq"
      },
      "source": [
        "ANSWER: The best value for alpha is about 0.01 with a score of 0.829. This is what I would expect because the mini training data set is not too large and thus requires a relatively larger alpha value. The accuracy when alpha is near 0, when there is very little smoothing at alpha=1e-10, has an accuracy of about 0.812, which is lower than the average accuracy that corresponds to the optimal alpha value. This makes sense as we are under-smoothing in the case where alpha is near 0. The alpha values near the optimal value (0.001 and 0.0001) have similar scores and are both ranked second best, based on the CV results.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQ6MaDU6TzOr"
      },
      "source": [
        "### Question 4: Experimenting with Gaussian Naive Bayes\n",
        "---\n",
        "1. Produce a model using Guassian Naive Bayes, which is intended for real-valued features, and evaluate performance. You will notice that it does not work so well. \n",
        "1. Diagnose and explain the problem.\n",
        "1. Apply a simple fix so that the model accuracy is around the same as for a Bernoulli Naive Bayes model. \n",
        "1. Show the model accuracy before your fix and the model accuracy after your fix.  \n",
        "1. Explain your solution.\n",
        "\n",
        "Notes:\n",
        "* Train on the mini train set.\n",
        "* Evaluate performance on the dev set.\n",
        "* Take a look at var_smoothing argument for GaussianNB.\n",
        "* Feel free to  examine theta and sigma to better understand what's happening. In general though, **it is not a good idea to mess with internal variables of the model**. These are stored in the model's `theta_` and `sigma_` attributes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqW86YbKTzOr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10dfc076-3440-4a88-e793-40526c2eebd3"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "def Q4():\n",
        "  '''Produces a model using Gaussian Naive Bayes and applies a simple fix so the model accuracy is the same as for a Bernoulli Naive Bayes model and displays model accuracy pre and post the change'''\n",
        "### STUDENT END ###\n",
        "  # Using GaussianNB to produce a model using Gaussian Naive Bayes: \n",
        "  gaussian_nb = GaussianNB() \n",
        "  # Fitting the Gaussian Naive Bayes model on the the mini train data and labels: \n",
        "  gaussian_nb.fit(mini_train_data, mini_train_labels) \n",
        "  # Predicting on dev data: \n",
        "  gaussian_nb_predicted = gaussian_nb.predict(dev_data) \n",
        "  # Obtaining accuracy of the model using accuracy_score and normalization:\n",
        "  gaussian_nb_accuracy_score = accuracy_score(dev_labels, gaussian_nb_predicted, normalize=True) \n",
        "\n",
        "  # Printing results/score: \n",
        "  print('Accuracy for Original Gaussian NB model:', gaussian_nb_accuracy_score) \n",
        "\n",
        "  # New line for stylistic purposes:\n",
        "  print('\\n') \n",
        "    \n",
        "  # Setting potential values for the var_smoothing, or the \"portion of the largest variance of all features that is added to variances for calculation stability\":\n",
        "  # Source: https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html\n",
        "  params_nb = {'var_smoothing': np.logspace(0, -9, num = 100)}\n",
        "\n",
        "  # Using GridSearchCV, like in part 3, to evaluate performance by cross-validation (with new param_grid): \n",
        "  gaussian_optimization = GridSearchCV(\n",
        "                  estimator = GaussianNB(),\n",
        "                  param_grid = params_nb,\n",
        "                  cv = 10,\n",
        "                  verbose=1, \n",
        "                  scoring='accuracy') \n",
        "  # Fitting it on the mini train data and labels: \n",
        "  gaussian_optimization.fit(mini_train_data, mini_train_labels)\n",
        "\n",
        "  # New line for stylistic purposes:\n",
        "  print('\\n') \n",
        "\n",
        "  # Printing out the var_smoothing value that yields the highest accuracy: \n",
        "  print(gaussian_optimization.best_params_)\n",
        "\n",
        "  # Using GaussianNB to produce a new model using Gaussian Naive Bayes with the optimized var_smoothing param: \n",
        "  new_gaussian_nb = GaussianNB(var_smoothing = 0.15199) \n",
        "  # Fitting the new Gaussian Naive Bayes model on the the mini train data and labels: \n",
        "  new_gaussian_nb.fit(mini_train_data, mini_train_labels) \n",
        "  # Predicting on dev data: \n",
        "  new_gaussian_nb_predicted = new_gaussian_nb.predict(dev_data) \n",
        "  # Obtaining accuracy of the new model using accuracy_score and normalization:\n",
        "  new_gaussian_nb_accuracy_score = accuracy_score(dev_labels, new_gaussian_nb_predicted, normalize=True) \n",
        "\n",
        "  # New line for stylistic purposes:\n",
        "  print('\\n') \n",
        "\n",
        "  # Printing results/score: \n",
        "  print('Accuracy for New Gaussian NB model:', new_gaussian_nb_accuracy_score) \n",
        "\n",
        "  # Messing around with the sigma internal var: \n",
        "  # possible_sigmas = [] \n",
        "  # new_accuracies = [] \n",
        "\n",
        "  # for i in np.arange(0, 1, 0.1): \n",
        "  #   gaussian_nb.sigma_ =  i\n",
        "  #   new_gaussian_nb_accuracy_score = accuracy_score(dev_labels, gaussian_nb_predicted, normalize=True) \n",
        "  #   new_accuracies.append(new_gaussian_nb_accuracy_score) \n",
        "\n",
        "  # print(new_accuracies) \n",
        "\n",
        "### STUDENT END ###\n",
        "\n",
        "Q4()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for Original Gaussian NB model: 0.459\n",
            "\n",
            "\n",
            "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "{'var_smoothing': 0.15199110829529336}\n",
            "\n",
            "\n",
            "Accuracy for New Gaussian NB model: 0.753\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:   17.5s finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wE5eQXsPTzOs"
      },
      "source": [
        "ANSWER: In order to improve the performance of the Guassian Naive Bayes model, I changed the value for the var_smoothing or the portions of the greatest variance of all the features that is added to variances within the Gaussian Naive Bayes model, since the Gaussian NB function holds a roughly normal distribution. Since the variance of the initial model is small and does not allow much variation in terms of fitting the mini train data to predict for the dev data. \n",
        "\n",
        "Using GridSearchCV considers all parameter combinations and allows me to tune the hyper-parameters for the Gaussian Naive Bayes model by providing the optimal var_smoothing value. Using this var_smoothing variable allows me to add the value fo the distribution's variance, which has a default value dependent on the mini train data set. As a result, this widens the distribution and allows for more variation in predicting on the dev data by accounting for more samples that are further from the mean of the distribution, essentially \"smoothening\" the curve. \n",
        "\n",
        "Although the new accuracy for the Gaussian Naive Bayes model, 0.753, is not as high as that for the Bernoulli Naive Bayes model, it is fairly close and much higher than before. \n",
        "\n",
        "Source: https://stackoverflow.com/questions/58046129/can-someone-give-a-good-math-stats-explanation-as-to-what-the-parameter-var-smoo#:~:text=The%20variable%2C%20var_smoothing%2C%20artificially%20adds,away%20from%20the%20distribution%20mean.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXx4SGNeTzOs"
      },
      "source": [
        "### Question 5: Naive Bayes as a generative model\n",
        "---\n",
        "Because Naive Bayes produces a generative model, you can use it to generate digit images.\n",
        "\n",
        "1. Produce a Bernoulli Naive Bayes model and then use it to generate a 10x10 grid with 10 example images of each digit. Each pixel output will be either 0 or 1: randomly generating a number and then comparing it to the estimated probability of the pixel being either 0 or 1.  Show the grid.\n",
        "1. How do the generated digit images compare to the training digit images?\n",
        "\n",
        "Notes:\n",
        "* You can use np.random.rand() to generate random numbers from a uniform distribution.\n",
        "* The estimated probability of each pixel being 0 or 1 is stored in the model's `feature_log_prob_` attribute. You can use `np.exp()` to convert a log probability back to a probability.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "WDCNbv7ETzOt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6919bf9e-51e8-4855-b715-5f29c84db4c4"
      },
      "source": [
        "def Q5(num_examples):\n",
        "  '''Produces a Bernoulli Naive Bayes model to generate a 10x10 grid of examples images for each digit'''\n",
        "  ### STUDENT START ###\n",
        "  # Using BernoulliNB to produce a model using Bernoulli Naive Bayes: \n",
        "  bernoulli_nb = BernoulliNB(binarize = 0.1) \n",
        "  # Fitting the model on the mini train data and mini train labels: \n",
        "  bernoulli_nb_fit = bernoulli_nb.fit(mini_train_data, mini_train_labels)\n",
        "\n",
        "  # Finding the estimated probability of each pixel being 0 or 1 is stored in the model's feature_log_prob_ attribute\n",
        "  # Using np.exp() to convert a log probability back to a probability\n",
        "  pixel_probabilities = np.exp(bernoulli_nb_fit.feature_log_prob_)\n",
        "\n",
        "  # Similar to number 1 in project 1, creating subplots with the number of rows equal to the number of unique elements in Y and the number of columns equal to 10, with a set figure size of 20x20:\n",
        "  fig, axs = plt.subplots(len(np.unique(Y)), 10, figsize=(20,20)) \n",
        "  \n",
        "  # Iterating through each of the 10 possible digit options: \n",
        "  for digit in range(10):\n",
        "    # Composing the grid variable with only images of digits that have higher probabilities than the ones that were randomly generated:\n",
        "    # Using np.random.rand() to generate random numbers from a uniform distribution:\n",
        "      grid = pixel_probabilities[digit] > np.random.rand(num_examples, 28 * 28)\n",
        "      # Iterating through the number of images to print for each digit (10 as per directions):\n",
        "      for image in range(num_examples): \n",
        "          # Reshaping and displaying the images: \n",
        "          axs[digit, image].imshow(grid[image].reshape((int(np.sqrt(X.shape[1])), int(np.sqrt(X.shape[1])))), cmap='Greys') \n",
        "          # Removing ticks and associated numerical values from each subplot: \n",
        "          axs[digit, image].set_xticks([], []) \n",
        "          axs[digit, image].set_yticks([], []) \n",
        "### STUDENT END ###\n",
        "\n",
        "Q5(10)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: MatplotlibDeprecationWarning: Passing the minor parameter of set_xticks() positionally is deprecated since Matplotlib 3.2; the parameter will become keyword-only two minor releases later.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: MatplotlibDeprecationWarning: Passing the minor parameter of set_yticks() positionally is deprecated since Matplotlib 3.2; the parameter will become keyword-only two minor releases later.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x1440 with 100 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ENXdzngTzOu"
      },
      "source": [
        "ANSWER: When comparing the generated digit images to the training digit images, the generated digits look a lot more blurry and scattered and are not too distinguishable or readable. Connecting this back to the course material, it is harder to tell which digit is being portrayed in each image becayse Naive Bayes makes the assumption that there is independence between all pixels, which are the features in this case, which is not necessarily a valid assumption here.\n",
        "\n",
        "The training digit images were binarized with a threshold of 0.1 such that a higher threshold corresponds to a blurrier image. After this, the dataset produced was dependent on the probability of the pixel having a higher probability compared to the randomly generated number. Therefore, if the shape of the number was not as clear or distinguishable, with variation in pixel values, it became more blurry."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRkUEi50TzOu"
      },
      "source": [
        "### Question 6: Model Calibraiton\n",
        "---\n",
        "Recall that:\n",
        " * a **strongly calibrated** classifier is rougly 90% accurate when it says it is 90% accurate. The model's estimated posterior probability of the predicted class is indeed 0.9. \n",
        " * A **weakly calibrated** classifier is more accurate when it \"says\" it is more accurate. The actual accuracy is higher when the model's estimated posterior probability is higher.\n",
        " * A **poorly calibrated** classifier has no positive correlation between the model's estimate posterior probability and the actual accuracy.\n",
        "\n",
        "1. Produce a Bernoulli Naive Bayes model.  \n",
        "1. Evaluate performance: \n",
        "  1. Partition the dev set into several buckets based on the estimated posterior probabilities of the predicted classes (predict_proba)\n",
        "    - Think of it as a bin in a histogram, where each bin groups a range of estimated posterior probabilities of the predicted classes (predict_proba).\n",
        "    - Then estimate the actual accuracy the classifier achieved for each bucket. \n",
        "    - So, for each prediction:\n",
        "       - Find the bucket whose range includes the estimated posterior probability, \n",
        "       - and update \"correct\" and \"total\" counters accordingly. \n",
        "       - Show the accuracy for each bucket.\n",
        "1. How would you characterize the calibration for this Bernoulli Naive Bayes model according to the definitions above?\n",
        "\n",
        "Notes:\n",
        "* Set LaPlace smoothing (alpha) to the optimal value (from part 8).\n",
        "* Set binarization threshold to 0.\n",
        "* Train on the mini train set.\n",
        "* Evaluate perfromance on the dev set.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Gz3NDY9TzOu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9306a9ba-84ef-4c35-ba8f-1ca93fc3b11d"
      },
      "source": [
        "def Q6(buckets, correct, total):\n",
        "  '''Produces a Bernoulli Naive Bayes model and evaluates performance by partitioning the dev set into several buckets based on the estimated posterior probabilities of the predicted classes'''\n",
        "  ### STUDENT START ###\n",
        "  # Using BernoulliNB to produce the model with the LaPlace smoothing set to the optimal value: \n",
        "  bernoulli_nb = BernoulliNB(alpha = 0.01, binarize = 0)\n",
        "  # Fitting the model on the mini train data and mini train labels: \n",
        "  bernoulli_nb.fit(mini_train_data, mini_train_labels)\n",
        "\n",
        "  # Iterating through the dev data: \n",
        "  for x in np.arange(0, len(dev_data), 1):\n",
        "      # Set the estimated posterior probabilities to the the probability of the predicted development data label being any digits from 0 - 9:\n",
        "      estimated_posterior_probs = bernoulli_nb.predict_proba(dev_data)[x]\n",
        "      # Bucket the data based on the max of the estimated posterior probabilities: \n",
        "      # We use the max of the estimated posterior probabilities because this is the predicted development data label, or the probability of the correct predicted digit given the digit:\n",
        "      the_list = iter(buckets.index(bucket) for bucket in buckets if max(estimated_posterior_probs) <= bucket)\n",
        "      bucketed = next(the_list)\n",
        "      # Increase the number corresponding to the total bucketed data: \n",
        "      total[bucketed] += 1\n",
        "      # If the bucketed data is correct out of the total data, then increase the number corresponding to the correct bucketed data: \n",
        "      if list(estimated_posterior_probs).index(max(estimated_posterior_probs)) == int(dev_labels[x]): \n",
        "          correct[bucketed] +=1         \n",
        "### STUDENT END ###\n",
        "\n",
        "buckets = [0.5, 0.9, 0.999, 0.99999, 0.9999999, 0.999999999, 0.99999999999, 0.9999999999999, 1.0]\n",
        "correct = [0 for i in buckets]\n",
        "total = [0 for i in buckets]\n",
        "\n",
        "Q6(buckets, correct, total)\n",
        "\n",
        "# For testing purposes: \n",
        "for x in range(len(buckets)):\n",
        "  if total[x] != 0:\n",
        "    print('bucket = %.13f     total = %3d     accuracy = %.2f' %(buckets[x], total[x], (correct[x] / total[x]) * 100) + \"%\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bucket = 0.9000000000000     total =  32     accuracy = 34.38%\n",
            "bucket = 0.9990000000000     total =  71     accuracy = 39.44%\n",
            "bucket = 0.9999900000000     total =  53     accuracy = 56.60%\n",
            "bucket = 0.9999999000000     total =  49     accuracy = 57.14%\n",
            "bucket = 0.9999999990000     total =  55     accuracy = 80.00%\n",
            "bucket = 0.9999999999900     total =  48     accuracy = 68.75%\n",
            "bucket = 0.9999999999999     total =  39     accuracy = 84.62%\n",
            "bucket = 1.0000000000000     total = 653     accuracy = 94.03%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PYLz-1STzOu"
      },
      "source": [
        "ANSWER: Based on the definitions above, I would characterize the calibration for this Bernoulli Naive Bayes model as weakly calibrated as the actual accuracy is not always higher when the model's estimated posterior probability is higher. A higher confidence corresponds to a higher accuracy, but for the case where the total is 48 and the bucket bound is 0.9999999999900, the accuracy is not higher than that corresponding to a lower estimated posterior probability hence the direction of the accuracy cannot be accurately predicted based on the posterior. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azUfK3B4tI2P"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIeZGen1TzOv"
      },
      "source": [
        "### Question 7 EXTRA CREDIT: Feature generation\n",
        "---\n",
        "1. Design new features to see if you can produce a Bernoulli Naive Bayes model with better performance.\n",
        "1. Show the accuracy of a model based on the original features and the accuracy of the model based on the new features.\n",
        "\n",
        "**Note that improving results is actually hard.**\n",
        "\n",
        "Here are a few ideas to get you started:\n",
        "- Try summing or averaging the pixel values in each row.\n",
        "- Try summing or averaging the pixel values in each column.\n",
        "- Try summing or averaging the pixel values in each square block. (pick various block sizes)\n",
        "- Try implementing [*maxpool*](https://computersciencewiki.org/index.php/Max-pooling_/_Pooling) features, taking a rolling maximum over sub-regions of a the image. \n",
        "- In any case, you can either transform the original data or add new \"features\" to it.\n",
        "\n",
        "Notes:\n",
        "* Train on the mini train set (enhanced to comprise the new features).\n",
        "* Evaulate performance on the dev set.\n",
        "* Ensure that your code is well commented."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GtYu5ezTzOv"
      },
      "source": [
        "def Q7():\n",
        "\n",
        "### STUDENT START ###\n",
        "\n",
        "### STUDENT END ###\n",
        "\n",
        "Q7()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hOkGA6Rufd6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
